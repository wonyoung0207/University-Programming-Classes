{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks\n",
    "\n",
    "* 이전 시간까지 만들었던 neural network은 똑똑하지는 않았죠 (training을 하지 않아 손글씨를 분류하지 못했습니다)\n",
    "* 궁극적으로 neural network은 다양한 function으로 fitting 될 수 있는 universal function approximator가 될 수 있습니다\n",
    "\n",
    "* 즉 training을 잘 거친 neural network은 손글씨 image를 분류하는 분류 function으로 변신이 가능한 것이죠\n",
    "* 더욱이, 낮은 복잡도 내에서 수행 가능합니다\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "* 수업에서 배운 것과 같이, 좋은 parameter를 찾는 과정을 위해서 *성능*을 측정할 수 있는 측도, 즉 **loss function**이 필요합니다\n",
    "* 예를 들어서 mean squared loss 는 regression 문제와 binary classification 문제에 적용 가능합니다 (classification을 위해서는 더 좋은 loss function이 존재합니다)\n",
    "\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "* 위 수식에서 $n$은 training sample의 수, $y_i$는 true labels, $\\hat{y}_i$은 예측입니다\n",
    "\n",
    "* 위 loss function을 network parmeter에 대해서 최소화하는 것이 *학습* 이죠\n",
    "* 최소 값을 찾는 과정은 **gradient descent**를 사용합니다\n",
    "* Gradient descent는 loss function의 기울기를 정보를 활용하여 최소값을 찾아가는 과정이죠 (이론강의 참고)\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions in PyTorch\n",
    "\n",
    "* 다음 과정으로, Pytorch에서 loss를 어떻게 연산하는지 배워보죠\n",
    "* `nn` module에서 다양한 loss function을 제공하는데, 예를 들면 `nn.CrossEntropyLoss`와 같은 함수가 있습니다\n",
    "    * 보통 관습적으로 loss function은 `critertion`이라는 변수로 받습니다 (`loss_function`등도 당연히 사용 가능합니다)\n",
    "* 지난 시간에 MNIST 문제는 확률 분포를 output으로 받는 것이 필요하다고 (또는 자연스러운 선택 임을) 학습했습니다 \n",
    "* 이런 확률 분포를 output으로 받는 경우 대응되는 좋은 loss function이 cross entropy입니다 (이론 강의에서 cross entropy가 무엇을 의미하는지 설명한 부분을 복습 해보세요)\n",
    "\n",
    "* Cross entropy의 정의는 \n",
    "\\begin{align*}\n",
    " H(P, Q) &= -\\mathbb{E}_{y\\sim P} \\log(Q(y)) \\\\\n",
    " &=-\\sum_{y\\in\\mathcal{Y}} P(y)\\log(Q(y))\n",
    "\\end{align*}\n",
    "* 위 식은 두 확률 분포의 \"거리\"를 표현하는 식이라고 배웠습니다\n",
    "* 위에서 $P(x)$는 $x$의 label을 one hot coding 한 vector이고 $Q(x)$는 softmax를 취한 network output입니다\n",
    "* One hot coding은 y label이 1이면 첫번째 자리만 '1'이고 나머지는 영인 벡터, y label이 $k$이면 $k$ 번째 자리만 '1'이고 나머지는 0인 벡터입니다\n",
    "\n",
    "* 예를들어서 y=2에 대한 one hot encoding\n",
    "\\begin{align*}\n",
    "y_\\textrm{one_hot}(2) &= \\begin{array}{cccccc}\n",
    "[0 & 1 & 0 & \\cdots & 0]\n",
    "\\end{array}\n",
    "\\end{align*}\n",
    "\n",
    "* 위 cross entropy 식에 대응 하는 방식은:\n",
    "\\begin{align*}\n",
    "P(y=2) = y_\\textrm{one_hot}(2)\n",
    "\\end{align*}\n",
    "\n",
    "* 또한, neural network의 마지막 linear layer의 output 값이 $z$라고 할때,\n",
    "\\begin{align*}\n",
    "Q(y=2) = \\sigma(z_2) = \\cfrac{\\exp(z_2)}{\\sum_k^K{\\exp(z_k)}}\n",
    "\\end{align*}\n",
    "\n",
    "<img src='assets/NLLLoss.jpg' width=550px>\n",
    "\n",
    "* pytorch에서 이를 수행하기 위해서 criterion을 `nn.CrossEntropyLoss`로 생성하고, network의 예측 값과, 실제 label 값을 입력으로 loss를 계산합니다\n",
    "  * 본 과정은 차근차근 설명하겠습니다\n",
    "* 그 전에 Pytorch에서 cross entropy 함수를 어떻게 적용하는지 먼저 이해할 필요가 있습니다 (중요합니다!!!)\n",
    "  * [Pytorch.org `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)를 살펴보면\n",
    "\n",
    "> This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    ">\n",
    "> The input is expected to contain scores for each class.\n",
    "\n",
    "* `nn.CrossEntropyLoss`는 `nn.LogSoftmax()`와 `nn.NLLLoss()` 하나의 class에서 수행한다고 되어 있습니다. \n",
    "* 두번째 줄에서 NLLLoss 는 negative log likelihood loss 입니다 \n",
    "\n",
    "* 이게 의미하는 바가 무엇이냐면, network의 output을 softmax function을 적용하여 출력하지 말고, softmax는 loss function에서 계산한다는 뜻입니다\n",
    "* 이렇게 구현한 이유는, 확률값이 작을 수 있어서 computation precision error를 방지하기 위해서 그냥 raw output 값을 받고, loss function에서 log(prob) 형태로 연산하도록 모듈을 구성하였습니다\n",
    "\n",
    "* 아래 코드를 보면 조금 더 이해가 될 것이라고 생각합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3077, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "# loss function 을 변수로 받음\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주어진 CrossEntropyLoss()를 사용하지 않고, 조금 더 구체적으로 직접 cross entropy loss를 구현할 수 있습니다\n",
    "* 예를 들어서 output에 log-softmax activation function을 적용하면: `nn.LogSoftmax` 또는 `F.log_softmax` ([자료](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax))\n",
    "  * 이점은 나중에 확률 값을 간단히 `torch.exp(output)`를 통해서 얻을 수 있습니다\n",
    "* 최종적으로 Cross entropy를 구하기 위해서는 log-softmax output에, loss function을 `nn.NLLLoss` ([자료](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss))로 정의하면 같은 효과입니다\n",
    "* Pytorch에서 NLLLoss 함수는 log probability를 입력으로 받음 \n",
    "  \n",
    "\n",
    ">**Exercise 1[5 points]:** \n",
    "* 위와 같은 네트워크에 마지막 layer을 LogSoftmax를 적용하고 (dim 옵션 필요)\n",
    "* `criterion`을 `nn.NLLLoss()`로 적용하는 네트워크를 구성하세요\n",
    "* output layer에 LogSoftmax를 적용하여 출력하고, NLLLoss를 loss function으로 활용합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3281, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "* 이제 loss function을 정의하고 loss 값을 구하는 방법을 알았으니, training (최적 parameter)을 찾기위한 작업을 수행합니다\n",
    "* 우리는 최적화 과정은 SGD (또는 유사 변형 알고리즘)를 통해서 수행하게 되는데, SGD를 수행하기 위해서는 또 Gradient를 구해야 한다는 것을 알고 있습니다\n",
    "* Pytorch의 가장 큰 장점은, 이런 gradient를 자동으로 구하기 위한 `autograd` 모듈을 제공합니다 (!!!!)\n",
    "* 내부적으로는 각 tensor가 어떤 변환은 격는지 기록을 통해서, 다시 각 연산을 역순 (backward)으로 gradient를 구하게 됩니다\n",
    "* 이런 과정을 backpropagation이라고 하는데, 나중에 더욱 자세히 배우도록 하고, 본 실습에서는 `autograd`모듈이 자동으로 계산해준다고 알고 사용하면 됩니다\n",
    "* Pytorch에서 tensor에 수행되는 연산을 기록하고자 할때 사용하는 중요한 keyword가 `requires_grad`이며, 사용 방법은 `x.requires_grad_(True)`\n",
    "\n",
    "* Training을 모두 끝내고, test단계에서는 gradient update을 하지 않기 때문에 불필요한 메모리/연산을 줄이기 위해서, gradient 연산에 필요한 연산과정 저장을 끄기 위해서 `torch.no_grad()`로 gradient를 비활성화 할 수 있습니다\n",
    "\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "* 비슷하게 gradient를 활성/비활성화를 `torch.set_grad_enabled(True|False)`를 통해서 할 수도 있습니다\n",
    "\n",
    "Gradient를 연산할때는 해당 tensor에 대해서 수행하며, 예를들어서 `z` tensor에 `z.backward()`라는 명령을 주면 gradient를 구합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3967,  2.0534,  1.4095,  1.2307]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1,4, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.7440, 4.2165, 1.9867, 1.5147]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* grad_fn을 통해서 `y` variable를 만들어낸 operation `PowBackward0`를 확인할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f86ca5ca290>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* autograd module은 위와 같은 operation 정보를 저장하면서, 각 operation에 대해서 gradient를 연산하는 방법을 갖고 있습니다\n",
    "* 위 과정을 미분에서 chain rule과 같은 형태의 연산을 통해서 gradient를 연산합니다\n",
    "* Gradient를 구하기 위해서 y tensor를 scalar 값으로 변환하는 연산을 추가해보죠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3655, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `x`와 `y`의 gradient를 구해볼 수 있는데, 아직은 비어있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gradient를 구하기 위해서 연산을 수행하고자 하는 variable에 `.backward` method를 실행합니다\n",
    "  * 예를 들어서 `z`에 z.backward()를 실행하면 $\\nabla_x z$를 구하게 되죠\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_x z = \\nabla_x \\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] &= \\left[\\frac{\\partial z}{\\partial x_1}, \\cdots,\\frac{\\partial z}{\\partial x_4}\\right]\\\\\n",
    "&=\\left[\\frac{x_1}{2},\\ldots,\\frac{x_4}{2}\\right]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1983,  1.0267,  0.7047,  0.6154]])\n",
      "tensor([[-1.1983,  1.0267,  0.7047,  0.6154]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()#gradient 구하기 위해 사용\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위와 같이 gradient를 구할 수 있으면, gradient descent를 수행할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Autograd together\n",
    "\n",
    "* Pytorch를 통해서 network를 설계할때에, 모든 parameter들은 `requires_grad = True` 상태로 초기화 됩니다\n",
    "* 이는, 최종적으로 forward pass output 값고 label 값을 통해서 `loss`를 계산하고, `loss.backward()`를 실행하여 loss function에 대한 gradient가 계산된다\n",
    "* 아래 예제를 통해서 gradient를 구하는 방법에 대한 예이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.4482, -2.1184, -2.3339, -2.4775, -2.2923, -2.1450, -2.4960, -2.1097,\n",
      "        -2.4508, -2.2591], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(logps[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 6, 0, 2, 1, 4, 7, 8, 8, 5, 8, 8, 9, 0, 0, 4, 4, 7, 2, 4, 1, 6, 3, 1,\n",
      "        6, 9, 1, 3, 4, 0, 8, 0, 1, 7, 6, 2, 0, 6, 7, 4, 7, 3, 1, 5, 1, 3, 2, 7,\n",
      "        3, 8, 3, 7, 3, 6, 1, 6, 2, 3, 4, 0, 8, 9, 2, 9])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3110, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 3.8830e-03,  3.8830e-03,  3.8830e-03,  ...,  3.8830e-03,\n",
      "          3.8830e-03,  3.8830e-03],\n",
      "        [ 3.9191e-04,  3.9191e-04,  3.9191e-04,  ...,  3.9191e-04,\n",
      "          3.9191e-04,  3.9191e-04],\n",
      "        [ 2.0803e-04,  2.0803e-04,  2.0803e-04,  ...,  2.0803e-04,\n",
      "          2.0803e-04,  2.0803e-04],\n",
      "        ...,\n",
      "        [ 1.8983e-04,  1.8983e-04,  1.8983e-04,  ...,  1.8983e-04,\n",
      "          1.8983e-04,  1.8983e-04],\n",
      "        [ 6.4207e-04,  6.4207e-04,  6.4207e-04,  ...,  6.4207e-04,\n",
      "          6.4207e-04,  6.4207e-04],\n",
      "        [-7.0917e-05, -7.0917e-05, -7.0917e-05,  ..., -7.0917e-05,\n",
      "         -7.0917e-05, -7.0917e-05]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "\n",
    "* 자, 그럼 network parameter에 대한 loss function의 gradient를 구했으니, 이제 최적화를 할 수 있습니다\n",
    "* 최적화 기법은 SGD 이외에도 많으며 (SGD의 변형들임) [`optim` package](https://pytorch.org/docs/stable/optim.html)에서 찾아서 사용할 수 있습니다\n",
    "* 예를 들어서 SGD는 `optim.SGD`를 통해서 불러올 수 있습니다\n",
    "* 아래 예를 보죠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "# 최적화기법 = SGD\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.parameters()는 우리 network의 모든 training parameter이며, lr는 learning rate 입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 자, 이제 traning에 필요한 모든 부분이 준비되었습니다\n",
    "* 전체 데이터에 대한 training은 숙제로 하고, 한 batch만 수행하는 과정을 살펴보죠\n",
    "* Pytorch에서 training의 전체 흐름은 다음과 같습니다:\n",
    "\n",
    "1. Network에서 forward pass\n",
    "2. Foward pass를 통해서 얻은 output을 활용하여 loss를 구한다\n",
    "3. Gradient를 구하기 위해서 `loss.backward()`를 실행한다\n",
    "4. Optimizer에서 weight를 한번 update 한다 (SGD의 경우 한 batch에 대해서 한번 update)\n",
    "\n",
    "**[중요]**\n",
    "* 한가지 주의할 점은, 한 Parameter들에 대해서 gradient를 여러개 구해야하는 경우, (예, batch 처리) gradient 값들은 계속 추가적으로 저장됩니다\n",
    "  * 다시말해서, sample 별로 gradient를 구한다고 생각하면, 한 batch에 여러 sample이 있으니, gradient를 여러개 구해야함\n",
    "* 한번 parameter update가 끝났으면, gradient 값을 초기화해야, 새로운 batch에 대한 새 gradient 값을 계산 합니다\n",
    "* 이를 위해서 batch 시작시에 `optimizer.zero_grad()`를 실행해줘야합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 7.3269e-03, -1.1780e-02,  1.4189e-02,  ...,  3.3650e-02,\n",
      "         -1.6210e-03, -1.3517e-02],\n",
      "        [ 4.9625e-03,  3.2961e-02, -1.2699e-02,  ..., -1.5103e-02,\n",
      "          1.7872e-02, -2.9852e-02],\n",
      "        [-1.9252e-02, -7.2896e-05, -4.9787e-03,  ...,  2.0619e-02,\n",
      "          6.2380e-03,  8.5239e-03],\n",
      "        ...,\n",
      "        [ 3.7467e-03,  2.3043e-02, -2.0215e-02,  ..., -1.9802e-02,\n",
      "         -2.6437e-02,  2.5590e-02],\n",
      "        [-2.0047e-02, -1.7321e-02, -6.7015e-03,  ...,  3.3838e-02,\n",
      "          3.0639e-02,  9.9998e-03],\n",
      "        [-3.0002e-02,  3.5499e-02, -1.5417e-02,  ..., -1.6629e-03,\n",
      "          9.2113e-03,  7.7953e-03]], requires_grad=True)\n",
      "Gradient - tensor([[ 0.0025,  0.0025,  0.0025,  ...,  0.0025,  0.0025,  0.0025],\n",
      "        [-0.0022, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0022],\n",
      "        [ 0.0031,  0.0031,  0.0031,  ...,  0.0031,  0.0031,  0.0031],\n",
      "        ...,\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
      "        [ 0.0025,  0.0025,  0.0025,  ...,  0.0025,  0.0025,  0.0025],\n",
      "        [ 0.0061,  0.0061,  0.0061,  ...,  0.0061,  0.0061,  0.0061]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "# gradient 값 초기화 -> 새로운 batch에 대한 새 gradient 계산하기 위해\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0073, -0.0118,  0.0142,  ...,  0.0336, -0.0016, -0.0135],\n",
      "        [ 0.0050,  0.0330, -0.0127,  ..., -0.0151,  0.0179, -0.0298],\n",
      "        [-0.0193, -0.0001, -0.0050,  ...,  0.0206,  0.0062,  0.0085],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0230, -0.0202,  ..., -0.0198, -0.0264,  0.0256],\n",
      "        [-0.0201, -0.0173, -0.0067,  ...,  0.0338,  0.0306,  0.0100],\n",
      "        [-0.0301,  0.0354, -0.0155,  ..., -0.0017,  0.0092,  0.0077]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for real\n",
    "\n",
    "> **Exercise 2 [20 points]:** \n",
    "\n",
    "1. 아래 loop 안에 training을 위한 코드를 완성하세요\n",
    "2. epoch는 전체 dataset을 한번 읽으면 1씩 증가합나다\n",
    "3. 총 5번 dataset을 사용하여 training을 수행한다는 뜻입니다\n",
    "4. 2번째 for loop은 batch 에 대한 for loop 입니다\n",
    "5. 각 batch마다 SGD (batch SGD)를 수행하도록 위에서 배운 모듈들을 사용하여 완성하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.027222572105017\n",
      "Training loss: 1.0060052240072792\n",
      "Training loss: 0.5815004786448692\n",
      "Training loss: 0.45194338328802763\n",
      "Training loss: 0.39791129586666124\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "#logsoftmax 씌운형태 넣어서 계산, loss function 의 변수\n",
    "criterion = nn.NLLLoss()\n",
    "#각 model의 파라미터(W,B,F)들을 가져온다.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)#최적화 하기 위해\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()# gradient 초기화 \n",
    "        output = model(images)\n",
    "        \n",
    "        #성능 측청하는 척도\n",
    "        #여기서 하는 연산은 P(X값만 1이고 나머지 다 0)와 Q(softmax 취한 output) 를 내적한 값에 -sum해준다.\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()# gradient 구하기 위해\n",
    "        #update하는 과정, 파라미터 바꿔줌\n",
    "        optimizer.step()\n",
    "         #running_loss에다가 loss값 더해줌, 한번 다 돌고나면 print해주고 다시 0으로 초기화함\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our network is brilliant. It can accurately predict the digits in our images. Next up you'll write the code for training a neural network on a more complex dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
